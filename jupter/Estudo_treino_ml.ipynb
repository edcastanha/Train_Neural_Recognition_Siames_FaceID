{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# Package                      Version\n",
    "# ---------------------------- --------\n",
    "# matplotlib                   3.7.2\n",
    "# opencv-python                4.8.0.74\n",
    "# tensorflow                   2.10.1\n",
    "# tensorflow-gpu               2.10.1\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import uuid\n",
    "from matplotlib import pyplot as plt\n",
    "# Importando dependencias de TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "\n",
    "# Modelos Base para redes neurais convolucionais com TensorFlow:\n",
    "# Model(input=[inputImage, inputVerification], output=[1,0])\n",
    "# Input(shape=(100,100,3))\n",
    "\n",
    "# Configurando uso de GPU e limites de memória\n",
    "# https://www.tensorflow.org/guide/gpu\n",
    "# https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        try:\n",
    "        # Habilita uso de memória da GPU\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print('GPU: ', gpu)\n",
    "        # Limita uso de memória da GPU\n",
    "        #    tf.config.experimental.set_virtual_device_configuration(gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "# Saída aguardada conforme GPU disponível:\"\"\"\" GPU:  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\"\"\"\"\n",
    "else:\n",
    "    print('Não foi localizado nenhuma GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pegando caminhos de pastas Imagens\n",
    "* Referencia    =>    (anchor)\n",
    "* Cadastro      =>    (positive)\n",
    "* Aleatórias    =>    (negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se as pasta (Positivo, Negativo e Ancora ) existem, senão criaremos\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')\n",
    "\n",
    "#  ID de teste para o usuário ( RA )\n",
    "userID = 1001\n",
    "\n",
    "# Capturar Imagens de Ancora\n",
    "POS_PATH_ID = os.path.join('data', 'positive',str(userID))\n",
    "if not os.path.exists(POS_PATH_ID):\n",
    "    os.makedirs(POS_PATH_ID)\n",
    "\n",
    "ANC_PATH_ID = os.path.join('data', 'anchor', str(userID))\n",
    "if not os.path.exists(ANC_PATH_ID):\n",
    "    os.makedirs(ANC_PATH_ID)\n",
    "\n",
    "# print(NEG_PATH)\n",
    "# print(ANC_PATH_ID)\n",
    "# print(POS_PATH_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| correndo imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos Base para redes neurais convolucionais com TensorFlow:\n",
    "anchor = tf.data.Dataset.list_files(ANC_PATH_ID +'\\*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH_ID +'\\*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH +'\\*.jpg').take(300)\n",
    "\n",
    "# # TEST: Imprimindo os caminhos das imagens\n",
    "# dir_test = anchor.as_numpy_iterator()\n",
    "# for i in range(10):\n",
    "#     print(dir_test.next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Pré Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "\n",
    "    # Ler o arquivo de imagem\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "\n",
    "    # Decodificar o arquivo de imagem com TensorFlow\n",
    "    img = tf.image.decode_jpeg(byte_img)\n",
    "\n",
    "    #  Redimensionar a imagem [100x100x3]\n",
    "    img = tf.image.resize(img, [100, 100])\n",
    "    img = img / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "# img = preprocess('data\\\\anchor\\\\1001\\\\c7d4d103-2496-11ee-ad27-00e04f0d8f2c.jpg')\n",
    "\n",
    "# print(f'Min: {img.numpy().min()} - Max:{img.numpy().max()}')\n",
    "\n",
    "# TEST: Imprimindo as imagens\n",
    "# plt.imshow(img)\n",
    "\n",
    "# tf.ones_like([1,1,1,1,1,444,4,43,2])\n",
    "# tf.zeros_like([0,1,0,3])\n",
    "# exemplos tf \n",
    "# (imfBase , imgPositiva) => 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n",
    "# (imgBase, imgNegativa) => 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "\n",
    "# tf.ones(len(anchor))\n",
    "# tf.zeros(len(anchor))\n",
    "\n",
    "# class_labels = tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))\n",
    "# iterador = class_labels.as_numpy_iterator()\n",
    "# iterador.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor , positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor , negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)\n",
    "# samples do resultado do dataset\n",
    "# amostras = data.as_numpy_iterator()\n",
    "# # amostras.next()\n",
    "# exemplo = amostras.next()\n",
    "# exemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Pré Processamento de imagens idênticas ou distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de verificação para 'gemeos', ou seja, se as são a mesma pessoa \n",
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return (preprocess(input_img), preprocess(validation_img), label)\n",
    "#  o parametro '*' em '*exemplo' é para desempacotar a tupla\n",
    "# resultado = preprocess_twin(*exemplo)\n",
    "# plt.imshow(resultado[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=(TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Build Datapipe para treinamento\n",
    "#  https://www.tensorflow.org/guide/data_performance\n",
    "#  https://www.tensorflow.org/guide/data\n",
    "\n",
    "data = data.map(preprocess_twin)\n",
    "data.cache()\n",
    "data.shuffle(buffer_size=1024)\n",
    "\n",
    "# Demonstrando separação de dados para treino e teste 1.0 para mesma pessoas  e 0.0 para pessoas diferentes (anchor , (positiva ou negativa), label)   ))\n",
    "# amostra2 = data.as_numpy_iterator()\n",
    "# len(amostra2.next())\n",
    "# exemplar = amostra2.next()\n",
    "# for i in range(10):\n",
    "#     exemplar = amostra2.next()\n",
    "#     print(exemplar[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Training partition\n",
    "# Podendo utilizar um percentual das imagens com 'round(len(data) * 0.5)' ou 'take(400)' para 400 imagens\n",
    "# print(round(len(data) * 0.5))\n",
    "train_data = data.take(round(len(data) * 0.7))\n",
    "# Criaremos lote com '16' imagens\n",
    "train_data = train_data.batch(16)\n",
    "# Creiaremos um buffer de 8 imagens para pré-carregamento\n",
    "train_data = train_data.prefetch(8)\n",
    "\n",
    "# EXEMPLO: Imprimindo o resultado do treino\n",
    "# train_samplas = train_data.as_numpy_iterator()\n",
    "# train_sampla = train_samplas.next()\n",
    "# print(train_sampla[0].shape)\n",
    "# Saída: (16, 100, 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
